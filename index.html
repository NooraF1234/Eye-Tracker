<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Eye Tracking and Blink Click</title>
</head>
<body>
    <div>Teachable Machine Eye Tracker</div>
    <button type="button" onclick="init()">Start Tracking</button>
    <div id="webcam-container"></div>
    <div id="label-container"></div>

    <!-- Import TensorFlow.js and Teachable Machine libraries -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>
    <script src="https://webgazer.cs.brown.edu/webgazer.js"></script>

    <script type="text/javascript">
        const URL = "eye_tracking_data/"; // Path to your Teachable Machine model
        let model, webcam, labelContainer, maxPredictions;
        let gazeDirection = "";
        let blinkDetected = false;

        // Initialize the model and setup the webcam
        async function init() {
            const modelURL = URL + "model.json";
            const metadataURL = URL + "metadata.json";

            // Load the Teachable Machine model
            model = await tmImage.load(modelURL, metadataURL);
            maxPredictions = model.getTotalClasses();

            // Setup webcam and start tracking
            const flip = true;
            webcam = new tmImage.Webcam(200, 200, flip); // width, height, flip
            await webcam.setup();
            await webcam.play();
            window.requestAnimationFrame(loop);

            // Append webcam to DOM
            document.getElementById("webcam-container").appendChild(webcam.canvas);
            labelContainer = document.getElementById("label-container");
            for (let i = 0; i < maxPredictions; i++) {
                labelContainer.appendChild(document.createElement("div"));
            }

            // Initialize WebGazer for gaze tracking
            webgazer.setGazeListener((data, elapsedTime) => {
                if (data) {
                    const x = data.x; // X coordinate of gaze
                    const y = data.y; // Y coordinate of gaze
                    console.log(`Gaze Coordinates - X: ${x}, Y: ${y}`);
                    // You can add code here to interact based on gaze position
                }
            }).begin();
        }

        // Function to handle blink-click action
        function handleBlinkClick() {
            if (blinkDetected) {
                console.log("Blink detected! Performing click...");
                // Simulate a click or perform any action here
                document.getElementById("webcam-container").style.backgroundColor = "yellow";
            }
        }

        // Continuously monitor gaze and blink status
        async function loop() {
            webcam.update(); // update the webcam frame
            await predict();
            window.requestAnimationFrame(loop);
        }

        // Modified predict function
        async function predict() {
            const prediction = await model.predict(webcam.canvas);
            prediction.forEach((pred) => {
                if (pred.className === "Blink" && pred.probability > 0.9) {
                    blinkDetected = true;
                    handleBlinkClick(); // Call function for blink-click action
                } else if (pred.className === "Looking Left" && pred.probability > 0.9) {
                    gazeDirection = "Left";
                } else if (pred.className === "Looking Right" && pred.probability > 0.9) {
                    gazeDirection = "Right";
                }
                // Reset blink after action
                blinkDetected = false;
            });
        }

        // Start init on page load
        window.onload = init;
    </script>
</body>
</html>
